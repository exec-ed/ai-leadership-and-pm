<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>facilitation-guide</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="facilitation-guide_files/libs/clipboard/clipboard.min.js"></script>
<script src="facilitation-guide_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="facilitation-guide_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="facilitation-guide_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="facilitation-guide_files/libs/quarto-html/popper.min.js"></script>
<script src="facilitation-guide_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="facilitation-guide_files/libs/quarto-html/anchor.min.js"></script>
<link href="facilitation-guide_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="facilitation-guide_files/libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="facilitation-guide_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="facilitation-guide_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="facilitation-guide_files/libs/bootstrap/bootstrap-d6a003b94517c951b2d65075d42fb01b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="pilot-scoping-exercise" class="level1">
<h1>PILOT SCOPING EXERCISE</h1>
<section id="staff-answers-debriefing-guide" class="level2">
<h2 class="anchored" data-anchor-id="staff-answers-debriefing-guide">Staff Answers &amp; Debriefing Guide</h2>
<p><strong>Activity Duration:</strong> 30 min exercise + 15-20 min debrief <strong>Difficulty:</strong> Medium <strong>Key Skill Being Tested:</strong> Constraint thinking, success metrics, risk awareness</p>
<hr>
</section>
<section id="staff-answer---model-solution" class="level2">
<h2 class="anchored" data-anchor-id="staff-answer---model-solution">STAFF ANSWER - MODEL SOLUTION</h2>
<p>This is what an excellent pilot scope looks like. Use this as your standard for what “good” performance means.</p>
<section id="section-1-pilot-scope-decisions" class="level3">
<h3 class="anchored" data-anchor-id="section-1-pilot-scope-decisions">SECTION 1: Pilot Scope Decisions</h3>
<p><strong>Primary Function (What the AI Actually Does):</strong> - ✓ <strong>Automate responses to SPECIFIC query types only</strong> - ✓ <strong>Assist human agents with AI-suggested responses</strong> - ✓ <strong>Automatically triage and route queries</strong></p>
<p><strong>Chosen Approach (Hybrid):</strong></p>
<p><em>“Phase 1: AI auto-responds to high-volume, low-complexity queries (order tracking, return policy questions). Phase 2: AI assists agents by suggesting responses they can review/edit before sending. Start with ~40% of current volume (1,000 queries/week).”</em></p>
<p><strong>Rationale:</strong> - <strong>Why limited scope?</strong> 80% of queries fall into 2-3 categories; targeting these maximizes learning with contained risk - <strong>Why hybrid approach?</strong> Builds team comfort + demonstrates value before full automation - <strong>Why 1,000 queries/week?</strong> Large enough to get meaningful data; small enough to manage failures; 6-week sample covers seasonal variation</p>
<hr>
</section>
<section id="section-2-success-metrics" class="level3">
<h3 class="anchored" data-anchor-id="section-2-success-metrics">SECTION 2: Success Metrics</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 30%">
<col style="width: 25%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Current Baseline</th>
<th>Pilot Target</th>
<th>How We Measure</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Response time for tracked queries</td>
<td>26 hours</td>
<td>4 hours</td>
<td>Ticketing system logs</td>
</tr>
<tr class="even">
<td>First contact resolution rate</td>
<td>61%</td>
<td>75%</td>
<td>Post-resolution surveys + escalation tracking</td>
</tr>
<tr class="odd">
<td>Customer satisfaction for AI-handled queries</td>
<td>Unknown</td>
<td>≥80%</td>
<td>Brief 1-question survey after interaction</td>
</tr>
<tr class="even">
<td>Agent time per query (assisted mode)</td>
<td>8 min</td>
<td>5 min</td>
<td>Time tracking in system</td>
</tr>
<tr class="odd">
<td>AI accuracy on routine queries</td>
<td>—</td>
<td>≥90%</td>
<td>Weekly audits of 5% of AI responses</td>
</tr>
</tbody>
</table>
<p><strong>Primary Success Criterion:</strong></p>
<p><em>“Customer satisfaction for AI-handled queries ≥80%. If customers hate it, it doesn’t matter if it’s fast—we won’t scale it.”</em></p>
<hr>
</section>
<section id="section-3-pilot-boundaries" class="level3">
<h3 class="anchored" data-anchor-id="section-3-pilot-boundaries">SECTION 3: Pilot Boundaries</h3>
<p><strong>IN SCOPE:</strong> - Query types: Order tracking (35% volume), Return/Refund policy (25% volume) - Volume: 1,000 queries/week (40% of normal 2,500 weekly volume) - Duration: 8 weeks (6 weeks live + 2 weeks buffer) - Team: Full customer service team sees AI; 2 agents volunteer for “assisted mode” testing - Customers: All customers who query during pilot period (no segmentation by channel initially)</p>
<p><strong>OUT OF SCOPE:</strong> 1. Product questions requiring detailed knowledge (deferred to Phase 2) 2. Technical support (app/website issues) - too complex for initial AI 3. Complaint escalations &amp; refund exceptions - requires human judgment 4. Phone channel - start with chat/email only</p>
<p><strong>Why these boundaries?</strong></p>
<p><em>“We need to prove competence before expanding. These two query types are high-volume, well-documented, and low-risk. Excludes scenarios requiring judgment, empathy, or exception handling.”</em></p>
<hr>
</section>
<section id="section-4-risk-mitigation" class="level3">
<h3 class="anchored" data-anchor-id="section-4-risk-mitigation">SECTION 4: Risk Mitigation</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 30%">
<col style="width: 22%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Risk</th>
<th>Likelihood</th>
<th>Impact</th>
<th>Mitigation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AI gives incorrect info to customers</td>
<td>Medium</td>
<td>High</td>
<td>Phase 1: All AI responses flagged as “suggested” with human review before send. Weekly accuracy audits.</td>
</tr>
<tr class="even">
<td>Customer service team resists AI</td>
<td>High</td>
<td>High</td>
<td>Involve team in design (test group volunteers). Frame as “helping you” not “replacing you.” Monthly feedback sessions.</td>
</tr>
<tr class="odd">
<td>Customers hate interacting with AI</td>
<td>Medium</td>
<td>Medium</td>
<td>Clear handoff to human if customer requests. “Talk to agent” button always visible. Monitor satisfaction continuously.</td>
</tr>
<tr class="even">
<td>Budget overrun</td>
<td>Low</td>
<td>High</td>
<td>Lock down vendor pricing upfront. Use open-source tools where possible. Allocate 15% contingency.</td>
</tr>
<tr class="odd">
<td>AI can’t handle query complexity</td>
<td>Medium</td>
<td>Medium</td>
<td>Set accuracy threshold at 90%; anything below triggers escalation to human. Build feedback loop into training.</td>
</tr>
<tr class="even">
<td>Data privacy/security issues</td>
<td>Low</td>
<td>High</td>
<td>Data anonymized in AI model. Queries encrypted in transit/at rest. No customer data leaves our servers. Weekly security review.</td>
</tr>
</tbody>
</table>
<p><strong>Top 3 Risks (Detailed Mitigation):</strong></p>
<p><strong>Risk #1: Team Resistance</strong> - Mitigation: Involve customer service manager &amp; 2 volunteer agents from day 1. Position AI as “your research assistant”—handles the repetitive stuff so they focus on hard problems. Show them the time savings. Celebrate early wins visibly.</p>
<p><strong>Risk #2: AI Accuracy Issues (Bad Customer Experiences)</strong> - Mitigation: Phase 1 = 100% human review before customer sees response. Set hard floor at 90% accuracy; below that, we pause and retrain. Weekly sample of 50 responses reviewed by manager. Immediate feedback loop to data scientist.</p>
<p><strong>Risk #3: Executive Pressure to Expand Too Fast</strong> - Mitigation: Define clear “scale” criteria upfront with CEO. Show weekly progress. Document every escalation. After 4 weeks, present data: “We’re at 87% satisfaction on routine queries, 94% on tracking. Ready to add return policy questions but NOT product support yet.”</p>
<hr>
</section>
<section id="section-5-resource-allocation" class="level3">
<h3 class="anchored" data-anchor-id="section-5-resource-allocation">SECTION 5: Resource Allocation</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Category</th>
<th>Allocation</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AI platform/software</td>
<td>$35,000</td>
<td>OpenAI API + GPT-4 for 6 months (lower cost than licensing)</td>
</tr>
<tr class="even">
<td>Implementation/Integration</td>
<td>$40,000</td>
<td>Consultant 2 days/week × 6 months to integrate with ticketing system &amp; CRM</td>
</tr>
<tr class="odd">
<td>Data preparation</td>
<td>$15,000</td>
<td>Cleaning 5 years of historical queries, building training set, labeling accuracy</td>
</tr>
<tr class="even">
<td>Training &amp; change management</td>
<td>$20,000</td>
<td>3 full-day workshops for team, monthly lunch-and-learns, 1:1 coaching for resistant agents</td>
</tr>
<tr class="odd">
<td>Testing &amp; quality assurance</td>
<td>$25,000</td>
<td>Dedicated QA person 0.5 FTE, weekly accuracy audits, customer satisfaction surveys</td>
</tr>
<tr class="even">
<td>Contingency reserve</td>
<td>$15,000</td>
<td>10% buffer for unexpected costs or scope adjustments</td>
</tr>
<tr class="odd">
<td><strong>TOTAL</strong></td>
<td><strong>$150,000</strong></td>
<td></td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="section-5b-timeline-milestones" class="level3">
<h3 class="anchored" data-anchor-id="section-5b-timeline-milestones">SECTION 5B: Timeline &amp; Milestones</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 29%">
<col style="width: 31%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Month</th>
<th>Key Activities</th>
<th>Success Criteria</th>
<th>Deliverables</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Month 1</strong></td>
<td>Data audit &amp; prep; vendor selection; team kickoff</td>
<td>Historical data clean &amp; labeled; vendor contract signed; team trained on AI basics</td>
<td>Data audit report; vendor SLA; training completion sign-offs</td>
</tr>
<tr class="even">
<td><strong>Month 2</strong></td>
<td>AI model training; integration build; team workshop</td>
<td>Model accuracy ≥85% on test set; integration working in staging; team comfortable with workflow</td>
<td>Model performance report; integration test results; team feedback</td>
</tr>
<tr class="odd">
<td><strong>Month 3</strong></td>
<td>Live pilot launch; daily monitoring; weekly reviews</td>
<td>90% AI accuracy in production; zero critical customer complaints; team confidence growing</td>
<td>Week 1-4 dashboard with metrics; incident log; team survey</td>
</tr>
<tr class="even">
<td><strong>Month 4</strong></td>
<td>Optimize based on real-world data; plan Phase 2</td>
<td>Sustain 90%+ accuracy; customer satisfaction ≥75%; decision point for expansion</td>
<td>Optimization recommendations; Phase 2 scope document</td>
</tr>
<tr class="odd">
<td><strong>Month 5</strong></td>
<td>Phase 2 expansion (return policy queries); scale testing</td>
<td>Expand to 2 query types with same accuracy metrics; identify process improvements</td>
<td>Phase 2 launch report; expanded accuracy metrics</td>
</tr>
<tr class="even">
<td><strong>Month 6</strong></td>
<td>Go/No-Go decision point; full analysis; recommendations</td>
<td>All success metrics met (or documented why not); clear recommendation for scale/pivot/kill</td>
<td>Final business case; scale-up plan or pivot strategy</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="section-6-gono-go-decision-criteria" class="level3">
<h3 class="anchored" data-anchor-id="section-6-gono-go-decision-criteria">SECTION 6: Go/No-Go Decision Criteria</h3>
<p><em>Evaluated at Month 3 &amp; Month 6</em></p>
<p><strong>✅ SCALE IT (Full Rollout Recommended)</strong></p>
<p>Criteria: 1. <strong>Satisfaction &amp; Accuracy:</strong> AI customer satisfaction ≥80% AND accuracy ≥92% for handled query types 2. <strong>Team Adoption:</strong> 80%+ of team actively using suggested responses; zero formal grievances; voluntary use extending beyond pilot group 3. <strong>Business Impact:</strong> Cost per query reduced by 40%+ AND response time under 4 hours for 90%+ of queries AND zero escalations due to AI error 4. <strong>Evidence:</strong> 6+ weeks of clean data showing consistent performance; customer feedback predominantly positive; no emerging technical risks</p>
<p><em>If all criteria met → Recommend scale to full customer base over 3-month rollout</em></p>
<hr>
<p><strong>🔄 PIVOT IT (Change Approach, Continue Initiative)</strong></p>
<p>Criteria: 1. <strong>Partial Success:</strong> Accuracy 85-92% OR satisfaction 75-80% (good but not great; suggests we’re on right track but approach needs tweaking) 2. <strong>Process Issues, Not Technology:</strong> Problem is integration/workflow, not AI capability (solvable through better process design) 3. <strong>Emerging Opportunity:</strong> Real-world data reveals better use case than originally planned (e.g., “AI is actually better at complaint triage than we expected”)</p>
<p><em>If met → Pivot to new scope and extend pilot 8 more weeks</em></p>
<hr>
<p><strong>❌ KILL IT (Stop Project)</strong></p>
<p>Criteria: 1. <strong>Fundamental Failure:</strong> Accuracy stuck below 85% after 6 weeks of optimization attempts OR customer satisfaction below 70% 2. <strong>Team Rejection:</strong> &gt;50% of team actively resists; escalations due to AI errors increase over time; safety concerns emerge 3. <strong>Business Case Broken:</strong> Cost savings don’t materialise (&gt;15% overrun) OR response time doesn’t improve significantly</p>
<p><em>If any criterion met → Stop pilot. Document learnings. Redirect budget to different approach</em></p>
<hr>
</section>
<section id="section-7-stakeholder-management" class="level3">
<h3 class="anchored" data-anchor-id="section-7-stakeholder-management">SECTION 7: Stakeholder Management</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 27%">
<col style="width: 36%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Stakeholder</th>
<th>Their Main Concern</th>
<th>Your Engagement Strategy</th>
<th>Frequency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>CEO</strong></td>
<td>Will this work? Will it hit the Q4 deadline? Is it worth the investment?</td>
<td>Monthly 15-min updates with 3 key metrics (satisfaction, accuracy, cost savings vs.&nbsp;plan). Frame as “learning fast, de-risking decision.”</td>
<td>Monthly</td>
</tr>
<tr class="even">
<td><strong>CFO</strong></td>
<td>Cost overrun? Will we get ROI?</td>
<td>Detailed budget tracker. Monthly cost updates. Show path to $500K annual savings once scaled. “Still within budget.”</td>
<td>Monthly</td>
</tr>
<tr class="odd">
<td><strong>Customer Service Manager</strong></td>
<td>Will this replace my team? How does it affect morale?</td>
<td>Position as “your assistant, not your replacement.” Involve in design. Highlight time savings. Show job security pathway.</td>
<td>Weekly</td>
</tr>
<tr class="even">
<td><strong>Customer Service Team</strong></td>
<td>Am I being replaced? Will this make my job harder?</td>
<td>Training sessions. Celebrate early wins publicly. Share customer feedback. “You’re the expert on hard problems; AI handles the tedious stuff.”</td>
<td>Weekly lunch-and-learns</td>
</tr>
<tr class="odd">
<td><strong>IT/Security</strong></td>
<td>Will this create security/compliance issues?</td>
<td>Share security audit results. Demonstrate data handling protocols. Monthly security review. “No data leaves our servers.”</td>
<td>As-needed, + monthly check-in</td>
</tr>
<tr class="even">
<td><strong>Customers</strong></td>
<td>How is my data protected? Will I get bad service?</td>
<td>Transparent communication: “You may chat with AI for order tracking. You can always request a human.” Emphasize speed benefit. Monitor feedback continuously.</td>
<td>Continuous (via satisfaction surveys)</td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="debriefing-strategy-for-pilot-scoping" class="level2">
<h2 class="anchored" data-anchor-id="debriefing-strategy-for-pilot-scoping">DEBRIEFING STRATEGY FOR PILOT SCOPING</h2>
<p><strong>TIMING:</strong> After exercise, immediately begin 15-20 min debrief while groups finish presenting.</p>
<p><strong>FORMAT:</strong> 1. <strong>Gallery Walk</strong> (5 min) - Groups post their responses on wall. Everyone reads other groups’ answers. 2. <strong>Group Share</strong> (5 min) - 1-2 groups present their scope decisions. Highlight differences in approach. 3. <strong>Facilitated Discussion</strong> (10 min) - Use the debriefing questions below.</p>
<hr>
</section>
<section id="key-debriefing-questions" class="level2">
<h2 class="anchored" data-anchor-id="key-debriefing-questions">KEY DEBRIEFING QUESTIONS</h2>
<section id="question-1-on-scope" class="level3">
<h3 class="anchored" data-anchor-id="question-1-on-scope">Question 1: On Scope</h3>
<p><strong>“Why did you choose to automate THESE specific query types? What would happen if you chose differently?”</strong></p>
<ul>
<li><em>Purpose:</em> Tests thinking about risk/value trade-offs</li>
<li><em>Staff model answer:</em> “35% of volume, simple to handle, low risk of errors. If we chose product questions (20% volume), higher risk of errors. If we chose complaints (5% volume), we learn nothing at scale.”</li>
<li><em>What you’re listening for:</em> Do they have rationale beyond gut feeling? Do they understand risk-value trade-offs?</li>
</ul>
<p><strong>“How big a pilot is ‘big enough’? At what point do you have enough data to make a scale/kill decision?”</strong></p>
<ul>
<li><em>Purpose:</em> Tests understanding of sample size and learning</li>
<li><em>Staff model answer:</em> “You need enough volume to hit edge cases (6-8 weeks minimum) but not so much that one failure cascades. 1,000 queries/week = good zone. 100 would be too small; 3,000 would be risky.”</li>
<li><em>Red flag:</em> “As big as possible” (too ambitious) or “Very small, like 50 queries” (learn nothing)</li>
</ul>
<hr>
</section>
<section id="question-2-on-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="question-2-on-trade-offs">Question 2: On Trade-offs</h3>
<p><strong>“You had $150K. What got cut, and why? What would you cut first if budget dropped to $75K?”</strong></p>
<ul>
<li><em>Purpose:</em> Tests constraint thinking and priority-setting</li>
<li><em>Staff model answer:</em> “Cut contingency first, then testing budget. Must keep data prep and training. Those are foundation.”</li>
<li><em>Note:</em> This leads into the Constraint Card exercise if you’re doing that later</li>
</ul>
<p><strong>“You set accuracy at 90%. Why not 95%? Why not 80%?”</strong></p>
<ul>
<li><em>Purpose:</em> Tests thinking about realistic vs.&nbsp;aspirational targets</li>
<li><em>Staff model answer:</em> “90% is practical—catches most issues, allows some escalation. 95% might take 3x longer to achieve. 80% = unacceptable risk.”</li>
<li><em>Red flag:</em> Arbitrary numbers without reasoning</li>
</ul>
<hr>
</section>
<section id="question-3-on-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="question-3-on-uncertainty">Question 3: On Uncertainty</h3>
<p><strong>“What was your biggest assumption in this plan? What could prove you wrong?”</strong></p>
<ul>
<li><em>Purpose:</em> Tests risk awareness</li>
<li><em>Staff model answer:</em> “Assumption: Team will embrace AI. Reality check: May face resistance. Mitigation: Involve volunteers, celebrate wins, frame as assistant.”</li>
<li><em>What you’re listening for:</em> Do they identify key assumptions? Do they think about how to test them?</li>
</ul>
<p><strong>“If you had to bet your career on this plan, what would you change?”</strong></p>
<ul>
<li><em>Purpose:</em> Forces them to surface what they’re uncertain about</li>
<li><em>Staff model answer:</em> “I’d get the customer service manager more involved earlier. They know reality better than our documents.”</li>
</ul>
<hr>
</section>
<section id="question-4-on-gono-go" class="level3">
<h3 class="anchored" data-anchor-id="question-4-on-gono-go">Question 4: On Go/No-Go</h3>
<p><strong>“At what point would you kill this project? Be honest—when is it ‘good enough’ vs.&nbsp;‘a waste of money’?”</strong></p>
<ul>
<li><em>Purpose:</em> Tests decision-making clarity</li>
<li><em>Staff model answer:</em> “Kill if accuracy stays below 85% after 6 weeks. We’ve learned the approach doesn’t work. Sunk cost doesn’t matter.”</li>
<li><em>Red flag:</em> “We’d never kill it” (no discipline) or “We’d kill it immediately if anything goes wrong” (no resilience)</li>
</ul>
<p><strong>“How would you communicate a kill decision to the CEO?”</strong></p>
<ul>
<li><em>Purpose:</em> Tests stakeholder communication</li>
<li><em>Staff model answer:</em> “We learned the tech isn’t ready for this use case. Better to discover now than after full rollout. Here’s what we’ll do instead [alternative plan].”</li>
</ul>
<hr>
</section>
</section>
<section id="key-learning-points-to-emphasize" class="level2">
<h2 class="anchored" data-anchor-id="key-learning-points-to-emphasize">KEY LEARNING POINTS TO EMPHASIZE</h2>
<p><strong>Land these points during or after debrief:</strong></p>
<section id="best-pilots-are-goldilocks" class="level3">
<h3 class="anchored" data-anchor-id="best-pilots-are-goldilocks">1. “Best pilots are ‘Goldilocks’”</h3>
<p>Not too ambitious (guaranteed failure), not too timid (learn nothing), but just right (prove value, manage risk).</p>
</section>
<section id="scope-is-your-most-powerful-tool" class="level3">
<h3 class="anchored" data-anchor-id="scope-is-your-most-powerful-tool">2. “Scope is your most powerful tool”</h3>
<p>Good project managers are great at boundary-setting. What you say NO to matters as much as what you say YES to.</p>
</section>
<section id="success-metrics-predict-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="success-metrics-predict-outcomes">3. “Success metrics predict outcomes”</h3>
<p>If your metrics don’t align with what matters to customers + stakeholders, you’ll “succeed” on paper and fail in reality.</p>
</section>
<section id="risk-management-is-stakeholder-management" class="level3">
<h3 class="anchored" data-anchor-id="risk-management-is-stakeholder-management">4. “Risk management is stakeholder management”</h3>
<p>Your biggest risks aren’t technical—they’re people. Plan for resistance, budget constraints, and changing priorities.</p>
</section>
<section id="gono-go-criteria-set-you-free" class="level3">
<h3 class="anchored" data-anchor-id="gono-go-criteria-set-you-free">5. “Go/No-Go criteria set you free”</h3>
<p>Define these upfront so you can make a kill decision without guilt. You’re not failing; you’re learning.</p>
</section>
<section id="scope-creep-kills-more-projects-than-technical-issues" class="level3">
<h3 class="anchored" data-anchor-id="scope-creep-kills-more-projects-than-technical-issues">6. “Scope creep kills more projects than technical issues”</h3>
<p>Your scoping document is your shield against “just one more query type.”</p>
<hr>
</section>
</section>
<section id="what-to-watch-for-as-facilitator" class="level2">
<h2 class="anchored" data-anchor-id="what-to-watch-for-as-facilitator">WHAT TO WATCH FOR (As Facilitator)</h2>
<section id="red-flags-during-exercise" class="level3">
<h3 class="anchored" data-anchor-id="red-flags-during-exercise">Red Flags During Exercise</h3>
<ul>
<li>❌ “Let’s automate everything” → Too ambitious; they’ll fail</li>
<li>❌ “Let’s do 10% to be safe” → Too timid; they learn nothing</li>
<li>❌ “We’ll figure out metrics during the project” → No clear success criteria</li>
<li>❌ “All these risks; we’ll manage them somehow” → No concrete mitigation</li>
</ul>
</section>
<section id="green-flags-what-good-looks-like" class="level3">
<h3 class="anchored" data-anchor-id="green-flags-what-good-looks-like">Green Flags (What Good Looks Like)</h3>
<ul>
<li>✓ “40% of queries, 2 query types, 8 weeks” → Good scope</li>
<li>✓ “Accuracy 90%, satisfaction 80%” → Good metrics</li>
<li>✓ “We’ll pause if accuracy stays below 85%” → Clear go/no-go</li>
<li>✓ “Team resistance is our top risk; here’s how we address it” → Risk awareness</li>
</ul>
<hr>
</section>
</section>
<section id="assessment-rubric" class="level2">
<h2 class="anchored" data-anchor-id="assessment-rubric">ASSESSMENT RUBRIC</h2>
<section id="strong-performance-9-10" class="level3">
<h3 class="anchored" data-anchor-id="strong-performance-9-10">Strong Performance (9-10)</h3>
<ul>
<li>Clear boundaries; specific query types; volume clearly defined; realistic timeline</li>
<li>3-5 specific, measurable metrics; clear baseline &amp; target; realistic &amp; achievable</li>
<li>Identifies 6+ risks; realistic likelihood/impact; mitigation plans are specific &amp; actionable</li>
<li>Maps all key stakeholders; understands their concerns; engagement strategy clear for each</li>
</ul>
</section>
<section id="good-performance-7-8" class="level3">
<h3 class="anchored" data-anchor-id="good-performance-7-8">Good Performance (7-8)</h3>
<ul>
<li>Scope defined but somewhat vague; query types mentioned but trade-offs unclear</li>
<li>3-5 metrics but some are vague; baselines clear; targets maybe ambitious</li>
<li>Identifies 4-5 key risks; mitigation plans exist but could be more detailed</li>
<li>Maps 5+ stakeholders; understands concerns; strategy exists but could be more specific</li>
</ul>
</section>
<section id="needs-development-5-6" class="level3">
<h3 class="anchored" data-anchor-id="needs-development-5-6">Needs Development (5-6)</h3>
<ul>
<li>Scope covers multiple options without clear rationale; unclear volume targets</li>
<li>&lt;3 metrics or too many; hard to measure; targets unclear</li>
<li>Identifies 2-3 risks; mitigation plans are generic</li>
<li>Maps 3-4 stakeholders; limited stakeholder thinking; generic engagement</li>
</ul>
</section>
<section id="not-yet-5" class="level3">
<h3 class="anchored" data-anchor-id="not-yet-5">Not Yet (&lt; 5)</h3>
<ul>
<li>Scope is too ambitious or too timid; no clear boundaries</li>
<li>No clear metrics or unmeasurable goals</li>
<li>Misses major risks; no real mitigation plans</li>
<li>Ignores stakeholder management or naive approach</li>
</ul>
<hr>
</section>
</section>
<section id="quick-debrief-flow-if-short-on-time" class="level2">
<h2 class="anchored" data-anchor-id="quick-debrief-flow-if-short-on-time">QUICK DEBRIEF FLOW (If Short on Time)</h2>
<p><strong>10-minute debrief version:</strong> 1. Gallery walk (2 min) 2. Ask Question 1 + Question 3 (5 min) - Listen to 1-2 answers each 3. Land the learning: “Best pilots are Goldilocks. You just proved you can think like a PM.” (3 min)</p>
<p><strong>20-minute debrief version:</strong> 1. Gallery walk (3 min) 2. Ask all 4 questions with follow-ups (12 min) 3. Land the learning + transition (5 min)</p>
<hr>
</section>
<section id="facilitator-tips" class="level2">
<h2 class="anchored" data-anchor-id="facilitator-tips">FACILITATOR TIPS</h2>
<p><strong>Don’t answer their questions directly:</strong> - ❌ Don’t say: “That’s the right scope size” - ✓ Do ask back: “Why did you choose that size? What data supports it?”</p>
<p><strong>Celebrate good thinking:</strong> - “Notice what you just did: You limited scope, identified the real stakeholder concern, and made a clear decision. That’s PM mastery.”</p>
<p><strong>Notice differences between groups:</strong> - “Interesting—Group A chose 40% volume, Group B chose 60%. Both solid reasoning. What’s the trade-off?”</p>
<p><strong>If a group is stuck:</strong> - “Start with risk. What’s your #1 concern? Build the scope around managing that.” - “What would the CEO ask? Start there.”</p>
<hr>
<p><strong>Next Activity:</strong> If doing Constraint Card exercise, refer back to their budget allocation and mention: “You’re about to test whether your plan survives under pressure.”</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>